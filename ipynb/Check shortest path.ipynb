{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for j in ['a','b']:\n",
    "    for i in range(3):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: [('sleek', 'about'), ('sleek', 'the'), ('forget', 'sleek'), ('forget', 'looks'), ('play', 'if'), ('play', 'it'), ('play', 'can'), ('play', \"'t\"), ('looks', 'play'), ('play', 'some'), ('dvds', 'of'), ('dvds', 'your'), ('dvds', 'real'), ('some', 'dvds'), ('forget', '.')]\n",
      "shortest path: 5\n",
      "shortest path: ['sleek', 'forget', 'looks', 'play', 'some', 'dvds']\n",
      "augmented edges: [(('sleek', 'JJ', 'obl'), ('about', 'IN', 'case')), (('sleek', 'JJ', 'obl'), ('the', 'DT', 'det')), (('forget', 'VB', 'root'), ('sleek', 'JJ', 'obl')), (('forget', 'VB', 'root'), ('looks', 'VBZ', 'advcl')), (('play', 'VB', 'advcl'), ('if', 'IN', 'mark')), (('play', 'VB', 'advcl'), ('it', 'PRP', 'nsubj')), (('play', 'VB', 'advcl'), ('can', 'MD', 'aux')), (('play', 'VB', 'advcl'), (\"'t\", 'RB', 'advmod')), (('looks', 'VBZ', 'advcl'), ('play', 'VB', 'advcl')), (('play', 'VB', 'advcl'), ('some', 'DT', 'obj')), (('dvds', 'NNS', 'nmod'), ('of', 'IN', 'case')), (('dvds', 'NNS', 'nmod'), ('your', 'PRP$', 'nmod:poss')), (('dvds', 'NNS', 'nmod'), ('real', 'JJ', 'amod')), (('some', 'DT', 'obj'), ('dvds', 'NNS', 'nmod')), (('forget', 'VB', 'root'), ('.', '.', 'punct'))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "sample = \"forget about the sleek looks if it can 't play some of your real dvds.\"\n",
    "o_word, t_word = 'sleek', 'dvds'\n",
    "\n",
    "doc = nlp(sample)\n",
    "# Load stanfordnlp's dependency tree into a networkx graph\n",
    "edges = []\n",
    "augmented_edges = []\n",
    "for token in doc.sentences[0].dependencies:\n",
    "    if token[0].text.lower() != 'root':\n",
    "        edges.append((token[0].text.lower(), token[2].text))\n",
    "        augmented_edges.append(((token[0].text.lower(), token[0].xpos, token[0].dependency_relation),(token[2].text.lower(), token[2].xpos, token[2].dependency_relation)))\n",
    "graph = nx.Graph(edges)\n",
    "# Get the length and path\n",
    "entity1 = o_word\n",
    "entity2 = t_word\n",
    "print('edges:', edges)\n",
    "print('shortest path:', nx.shortest_path_length(graph, source=entity1, target=entity2))\n",
    "print('shortest path:', nx.shortest_path(graph, source=entity1, target=entity2))\n",
    "print('augmented edges:', augmented_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ['This is easy-to-use.', 'This is all-around.', 'This is brand-new.', 'This is eye-catching.']\n",
    "for sample in samples:\n",
    "    doc = nlp(sample)\n",
    "    # Load stanfordnlp's dependency tree into a networkx graph\n",
    "    edges = []\n",
    "    augmented_edges = []\n",
    "    for token in doc.sentences[0].dependencies:\n",
    "        if token[0].text.lower() != 'root':\n",
    "            edges.append((token[0].text.lower(), token[2].text))\n",
    "            augmented_edges.append(((token[0].text.lower(), token[0].xpos, token[0].dependency_relation),(token[2].text.lower(), token[2].xpos, token[2].dependency_relation)))\n",
    "    graph = nx.Graph(edges)\n",
    "    # Get the length and path\n",
    "    entity1 = 'best'.lower()\n",
    "    entity2 = 'iPod'\n",
    "    print('edges:', edges)\n",
    "    print('shortest path:', nx.shortest_path_length(graph, source=entity1, target=entity2))\n",
    "    print('shortest path:', nx.shortest_path(graph, source=entity1, target=entity2))\n",
    "    print('augmented edges:', augmented_edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
