{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "from DependencyGraph import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['quality']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_targets(token2idx, nodes, o, one_rel):\n",
    "    new_targets = set()\n",
    "    indices = token2idx[o]\n",
    "    for o_idx in indices:\n",
    "\n",
    "        # O(JJ) ~ MR <- T(NN)   *The phone has a big \"screen\"\n",
    "        if nodes[o_idx].dep == one_rel:\n",
    "            new_targets.add(nodes[nodes[o_idx].governor].token)\n",
    "\n",
    "        # O(JJ) -> MR ~ T(NN)   *The \"screen\" is big\n",
    "        child_nodes = [nodes[i] for i in range(len(nodes)) if nodes[i].governor==o_idx]\n",
    "        new_targets.update([child_node.token for child_node in child_nodes if child_node.dep == one_rel])\n",
    "\n",
    "    # This is for expanding the opinion targets from single word to phrases (e.g., battery life)\n",
    "    return list(new_targets)\n",
    "\n",
    "sample = 'The photo quality is amazing'\n",
    "doc = nlp(sample)\n",
    "\n",
    "sentence_graph = DependencyGraph(doc.sentences[0])\n",
    "extract_targets(sentence_graph.token2idx, sentence_graph.nodes, 'amazing', 'nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pod']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def next_focused_tokens(current_tokens, token2idx, nodes, dep_rel):\n",
    "    focused_tokens = set()\n",
    "    for current_token in current_tokens:\n",
    "        indices = token2idx[current_token]\n",
    "        for current_token_idx in indices:\n",
    "\n",
    "            if nodes[current_token_idx].dep == dep_rel: focused_tokens.add(nodes[nodes[current_token_idx].governor].token)\n",
    "            child_nodes = [nodes[i] for i in range(len(nodes)) if nodes[i].governor==current_token_idx]\n",
    "            focused_tokens.update([child_node.token for child_node in child_nodes if child_node.dep == dep_rel])\n",
    "    return focused_tokens\n",
    "\n",
    "def extract_targets(token2idx, nodes, o, dep_rels):\n",
    "\n",
    "    focused_tokens = [o]\n",
    "    for i in range(len(dep_rels)):\n",
    "        focused_tokens = next_focused_tokens(focused_tokens, token2idx, nodes, dep_rels[i])\n",
    "    \n",
    "    return list(focused_tokens)\n",
    "\n",
    "\n",
    "sample = 'Pod is the best mp3 player'\n",
    "doc = nlp(sample)\n",
    "\n",
    "sentence_graph = DependencyGraph(doc.sentences[0])\n",
    "extract_targets(sentence_graph.token2idx, sentence_graph.nodes, 'best', ['amod', 'nsubj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['quality']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'The photo quality is amazing'\n",
    "doc = nlp(sample)\n",
    "sentence_graph = DependencyGraph(doc.sentences[0])\n",
    "\n",
    "extract_targets(sentence_graph.token2idx, sentence_graph.nodes, 'amazing', ['nsubj'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
